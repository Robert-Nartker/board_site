# tactiq.io free youtube transcript
# NVIDIA CEO Jensen Huang Keynote at CES 2025
# https://www.youtube.com/watch/k82RwXqZHY8

00:00:06.600 this is how intelligence is
00:00:10.880 made a new kind of
00:00:14.000 factory generator of
00:00:17.359 tokens the building blocks of
00:00:21.039 AI tokens have opened a new frontier the
00:00:24.800 first step into an extraordinary world
00:00:27.359 where endless possibilities are born
00:00:34.760 tokens transform words into knowledge
00:00:37.879 and breathe life into
00:00:41.920 images they turn ideas into
00:00:46.199 videos and help us safely navigate any
00:00:51.520 environment tokens teach robots to move
00:00:54.359 like the Masters
00:01:00.399 Inspire new ways to celebrate our
00:01:02.680 victories a martini pleas call light
00:01:06.560 up thank you
00:01:09.360 Adam and give us peace of mind when we
00:01:12.119 need it most hi moroka hi Anna it's good
00:01:16.640 to see you again hi Emma we're going to
00:01:19.479 take your blood sample today okay don't
00:01:21.720 worry I'm going to be here the whole
00:01:26.159 time they bring meaning to numbers
00:01:30.759 to help us better understand the world
00:01:32.680 around
00:01:40.680 us predict the dangers that surround
00:01:51.119 us and find cures for the threats within
00:01:54.200 us
00:02:01.799 tokens can bring our Visions to
00:02:10.120 life and restore what we've
00:02:15.800 lost
00:02:17.319 Zachary I got my voice back
00:02:22.640 buddy they help us move
00:02:26.239 forward one small step at a time
00:02:35.519 and one giant
00:02:38.080 leap
00:02:53.159 together and
00:02:56.680 here is where it all begins
00:03:07.080 welcome to the stage Nvidia founder and
00:03:09.480 CEO Jensen
00:03:20.000 Wong welcome to
00:03:24.319 CES are you excited to be in Las
00:03:27.799 Vegas do you like my Jack
00:03:32.040 it I thought I'd go the other way from
00:03:34.959 Gary
00:03:37.000 Shapiro I'm in Las Vegas after all if
00:03:40.080 does if this doesn't work out if all of
00:03:42.400 you
00:03:44.040 object well just get used to it I think
00:03:47.080 I really think you have to let this sink
00:03:50.439 in in another hour or so you're going to
00:03:53.040 feel good about
00:03:56.959 it well uh welcome to
00:04:01.120 Nvidia in fact you're inside nvidia's
00:04:03.720 digital
00:04:04.959 twin and we're going to take you to
00:04:08.480 Nvidia ladies and gentlemen welcome to
00:04:13.760 Nvidia your
00:04:15.560 inside our digital
00:04:20.238 twin everything here is generated by
00:04:26.080 AI it has been an extraordinary Journey
00:04:28.960 extraordinary year here and uh it
00:04:32.720 started in 1993 ready go with
00:04:38.080 mv1 we wanted to build computers that
00:04:41.479 can do things that normal computers
00:04:44.000 couldn't and mv1 made it possible to
00:04:47.400 have a game console in your
00:04:49.639 PC our programming architecture was
00:04:52.400 called
00:04:53.759 UD missing the letter c until a little
00:04:56.840 while later but UDA UniFi Unified device
00:05:00.440 architecture and the first developer for
00:05:04.080 UDA and the first application that ever
00:05:06.639 worked on UDA was sega's Virtual
00:05:10.960 Fighter six years later we invented in
00:05:15.520 1999 the programmable
00:05:18.280 GPU and it
00:05:20.280 started 20 years 20 plus years of
00:05:24.520 incredible advance in this incredible
00:05:27.600 processor called the GPU it made modern
00:05:31.080 computer Graphics
00:05:33.160 possible and now 30 years later sega's
00:05:37.720 Virtual Fighter is completely
00:05:42.039 cinematic this is the new Virtual
00:05:44.680 Fighter project that's coming I just
00:05:46.639 can't wait absolutely
00:05:49.319 incredible six years after that six year
00:05:52.319 six years after
00:05:53.880 1999 we invented Cuda so that we could
00:05:58.960 explain or or expressed the
00:06:01.199 programmability of our gpus to a rich
00:06:04.240 set of algorithms that could benefit
00:06:05.720 from it Cuda
00:06:08.039 initially was difficult to explain and
00:06:11.240 it took years in fact it took
00:06:13.680 approximately six years somehow six
00:06:17.720 years later six years later or
00:06:22.319 so
00:06:25.360 2012 Alex kvki ilas sus and Jeff Hinton
00:06:30.639 discovered Cuda used it to process
00:06:34.919 alexnet and the rest of it is history AI
00:06:38.960 has been advancing at an incredible Pace
00:06:41.199 since started with perception AI we now
00:06:45.240 can understand images and words and
00:06:47.680 sounds to generative AI we can generate
00:06:51.199 images and text and
00:06:52.880 sounds and now agentic ai AIS that can
00:06:58.479 perceive reason plan and act and then
00:07:02.879 the next phase some of which we'll talk
00:07:04.759 about tonight physical AI 2012 now
00:07:10.280 magically
00:07:12.319 2018 something happened that was pretty
00:07:15.960 incredible Google's Transformer was
00:07:19.120 released as Bert and the world of AI
00:07:24.199 really took off Transformers as you know
00:07:28.280 completely changed the land landcape for
00:07:30.039 artificial intelligence in fact it
00:07:32.360 completely changed the landscape for
00:07:34.680 computing
00:07:35.639 altogether we recognized properly that
00:07:38.720 AI was not just a new application with a
00:07:42.680 new business opportunity but AI more
00:07:46.840 importantly machine learning enabled by
00:07:49.440 Transformers was going to fundamentally
00:07:51.919 change how Computing works and
00:07:56.000 today Computing is revolutionized in
00:08:00.159 every single layer from hand coding
00:08:04.159 instructions that run on CPUs to create
00:08:07.000 software tools that humans use we now
00:08:09.960 have machine learning that creates and
00:08:12.919 optimizes new networks that processes on
00:08:16.199 gpus and creates artificial
00:08:19.000 intelligence every single layer of the
00:08:21.479 technology stack has been completely
00:08:24.440 changed an incredible transformation in
00:08:28.199 just 12 years
00:08:30.400 well we can Now understand information
00:08:33.719 of just about any modality surely you've
00:08:37.000 seen text and images and sounds and
00:08:39.479 things like that but not only can we
00:08:42.479 understand those we can understand amino
00:08:44.399 acids we can understand physics we
00:08:47.240 understand them we can translate them
00:08:49.480 and generate them the applications are
00:08:52.440 just completely endless in fact almost
00:08:55.000 any AI application that you you see out
00:08:57.760 there what modality is the input that it
00:09:00.440 learned from what modality of
00:09:02.959 information did it translate to and what
00:09:05.600 modality of information is it generating
00:09:07.839 if you ask these three fundamental
00:09:09.360 questions just about every single
00:09:11.200 application could be inferred and so
00:09:14.519 when you see application after
00:09:16.480 applications that are Aid driven AI
00:09:19.920 native at the core of it this
00:09:22.240 fundamental concept is there machine
00:09:24.440 learning has changed how every
00:09:26.480 application is going to be built how
00:09:28.880 computing will be done and the
00:09:31.279 possibilities Beyond
00:09:33.880 well
00:09:35.920 gpus gForce in a lot of
00:09:39.680 ways all of this with AI is the house
00:09:42.920 that GeForce built GeForce enabled AI to
00:09:47.000 reach the masses and now ai is coming
00:09:51.000 home to
00:09:52.000 GeForce there are so many things that
00:09:54.240 you can't do without AI let me show you
00:09:58.839 some of it
00:09:59.880 now
00:11:34.959 that was realtime computer
00:11:44.360 Graphics no computer Graphics researcher
00:11:47.839 no computer scientist would have told
00:11:50.240 you that it is possible for us to rate
00:11:52.800 trce every single Pixel at this point we
00:11:56.880 Ray tracing is a simulation of light the
00:11:59.399 amount of geometry that you saw was
00:12:01.079 absolutely insane it would have been
00:12:03.360 impossible without artificial
00:12:05.399 intelligence there are two fundamental
00:12:07.560 things that we did we used of course
00:12:10.720 programmable shading and Ray traced
00:12:13.160 acceleration to produce incredibly
00:12:15.199 beautiful pixels but then we have
00:12:18.040 artificial
00:12:19.320 intelligence be
00:12:21.519 conditioned be controlled by that pixel
00:12:24.519 to generate a whole bunch of other
00:12:26.760 pixels not only is it able to generate
00:12:29.320 pixels spatially because it's aware of
00:12:32.639 what the colors should be it has been
00:12:35.000 trained on a supercomputer back in
00:12:37.160 Nvidia and so the neuron Network that's
00:12:39.279 running on the GPU can infer and predict
00:12:43.440 the pixels that we did not render not
00:12:46.839 only can can we do that it's called
00:12:49.240 dlss the latest generation of dlss also
00:12:53.000 generates Beyond frames it can predict
00:12:55.720 the future generating three additional
00:12:58.519 frames for every frame that we calculate
00:13:01.880 what you saw if we just said four frames
00:13:04.399 of what you saw because we're going to
00:13:06.440 render one frame and generate three if I
00:13:09.320 said four frames at full HD 4K that's 33
00:13:13.519 million pixels or so out of that 33
00:13:17.120 million
00:13:18.399 pixels we computed only
00:13:23.279 two it is an absolute miracle that we
00:13:27.000 can computationally comput tionally
00:13:29.519 using programmable shaders and our R
00:13:31.519 traced engine R tracing engine to
00:13:33.560 compute 2 million pixels and have ai
00:13:36.399 predict all of the other 33 and as a
00:13:40.600 result we're able to render at
00:13:43.279 incredibly high performance because AI
00:13:46.120 does a lot less computation it takes of
00:13:49.279 course an enormous amount of training to
00:13:51.399 produce that but once you train it the
00:13:54.160 generation is extremely efficient so
00:13:57.320 this is one of the incredible cap
00:13:59.160 abilities of artificial intelligence and
00:14:01.759 that's why there's so many amazing
00:14:03.440 things that are happening we used gForce
00:14:06.519 to enable artificial intelligence and
00:14:08.600 now artificial intelligence is
00:14:10.320 revolutionizing
00:14:11.720 GeForce everyone today we're announcing
00:14:15.120 our next
00:14:16.519 Generation the RTX Blackwell family
00:14:20.399 let's take a look
00:14:45.079 is
00:15:19.320 here it
00:15:20.519 is our brand new
00:15:23.160 gForce
00:15:24.880 RTX 50 Series Blackwell architect
00:15:30.040 the GPU is just a beast 92 billion
00:15:34.680 transistors
00:15:36.560 4,000 tops four pedop flops of AI three
00:15:41.959 times higher than the last generation
00:15:43.880 Ada and we need all of it to generate
00:15:46.199 those pixels that I showed you 380 Ray
00:15:50.120 tracing Tera flops so that we could for
00:15:53.199 the pixels that we have to compute
00:15:54.880 compute the most beautiful image you
00:15:56.839 possibly can and of course 125 Shader
00:16:00.720 teraflops there is actually a concurrent
00:16:03.319 Shader teraflops as well as an Inger
00:16:05.680 unit of equal performance so two dual
00:16:09.079 shaders one is for floating point one is
00:16:11.560 for integer G7 memory from Micron 1.8
00:16:16.959 terabytes Per Second Twice the
00:16:18.800 performance of our last generation and
00:16:20.920 we now have the ability to intermix AI
00:16:24.040 workloads with computer graphics
00:16:26.279 workloads and one of the amazing things
00:16:28.319 about this gener eration is the
00:16:30.000 programmable Shader is also able to now
00:16:34.279 process neuron networks so the Shader is
00:16:37.240 able to carry these neuron networks and
00:16:39.360 as a result we invented neurot texture
00:16:42.519 compression and neurom material shading
00:16:45.920 as a result of that you get these
00:16:47.639 amazingly beautiful images that are only
00:16:50.120 possible because we use AIS to learn the
00:16:53.040 texture learn a compression algorithm
00:16:56.120 and as a result get extraordinary
00:16:57.639 results okay so this is this is uh the
00:17:01.720 brand
00:17:02.920 new
00:17:05.160 RTX Blackwell
00:17:10.280 9
00:17:11.959 now even even the even the mechanical
00:17:15.400 design is a miracle look at this it's
00:17:17.400 got two
00:17:18.559 fans this whole graphics card is just
00:17:21.359 one giant fan you know so the question
00:17:24.199 is where's the graphics card is it
00:17:25.559 literally this
00:17:27.039 big the voltage regul to design is
00:17:30.760 state-of-the-art incredible design the
00:17:33.240 engineering team did a great job so here
00:17:35.679 it is thank
00:17:42.000 you okay so those are the speeds and
00:17:44.559 fees so how does it
00:17:46.240 compare
00:17:48.640 well this is RTX
00:17:53.200 490 I know I know many of you have
00:17:57.640 one I I know it look it's
00:18:01.720 $1,599 it is one of the best investments
00:18:04.280 you could possibly
00:18:06.080 make you for
00:18:08.640 $15.99 you bring it home to your
00:18:12.799 $10,000 PC
00:18:15.360 entertainment Command Center isn't that
00:18:18.400 right don't tell me that's not true
00:18:21.320 don't be
00:18:23.000 ashamed it's liquid
00:18:25.640 cooled fancy lights all over it
00:18:29.960 you lock it when you
00:18:33.000 leave it's it's the modern home theater
00:18:36.120 it makes perfect sense and now for
00:18:38.600 $1,500 and99
00:18:40.679 $15.99 you get to upgrade that and
00:18:42.880 turbocharged the living Daya lights out
00:18:44.320 of it well now with the Blackwell family
00:18:46.679 RTX 570 490 performance at 549
00:19:01.720 impossible without artificial
00:19:03.480 intelligence impossible without the Four
00:19:07.159 Tops four ter Ops of AI tensor cores
00:19:12.000 impossible without the G7 memories okay
00:19:14.880 so 5070 490 performance $549 and here's
00:19:19.720 the whole family starting from 5070 all
00:19:22.600 the way up to 5090 5090 twice the
00:19:25.640 performance of a 4090
00:19:30.799 starting of course we're producing at
00:19:33.520 very large scale availability starting
00:19:35.679 January well it is incredible but we
00:19:39.000 managed to put these in in gigantic
00:19:43.120 performance gpus into a laptop this is a
00:19:47.720 570 laptop for
00:19:51.080 $12.99 this 570 laptop has a 4090
00:19:55.640 performance I think there's one here
00:19:57.559 somewhere
00:20:00.400 let me show you
00:20:02.480 this this is a look at this thing here
00:20:06.600 let me
00:20:07.840 here there's only so many
00:20:10.880 pockets ladies and gentlemen Janine
00:20:17.000 Paul so can you imagine you get this
00:20:19.760 incredible graphics card here Blackwell
00:20:21.799 we're going to shrink it and put it in
00:20:23.320 put it in there does that make any
00:20:26.640 sense well you can't do that without
00:20:29.159 artificial intelligence and the reason
00:20:30.799 for that is because we're generating
00:20:32.960 most of the pixels using pixels using
00:20:34.919 our tensor cores so we retrace only the
00:20:37.559 pixels we need and we generate using
00:20:40.280 artificial intelligence all the other
00:20:41.919 pixels we have as a result the amount of
00:20:44.320 the Energy Efficiency is just off the
00:20:46.520 charts the future of computer Graphics
00:20:49.400 is neural rendering the fusion of
00:20:51.799 artificial intelligence and computer
00:20:53.200 graphics and what's really
00:20:57.159 amazing is oh here we go thank
00:21:00.640 you this is a surprisingly kinetic
00:21:04.440 keynote and and uh what's really amazing
00:21:07.080 is the family of gpus we're going to put
00:21:08.919 in here and so the 1590 the 1590 will
00:21:13.720 fit into a laptop a thin laptop that
00:21:15.840 last laptop was 14 14.9 mm you got a
00:21:19.440 5080 5070 TI and
00:21:22.240 5070 okay so ladies and gentlemen the
00:21:26.559 RTX Blackwell family
00:21:37.520 well GeForce uh brought AI to to the
00:21:41.520 world democratized AI now ai has come
00:21:45.480 back and revolutionized GeForce let's
00:21:48.840 talk about artificial intelligence let's
00:21:51.360 go to somewhere else at
00:21:57.360 Nvidia this this is literally our office
00:21:59.919 this is literally nvidia's
00:22:03.480 headquarters okay so let's talk about
00:22:05.640 let's talk about AI the
00:22:08.640 industry is chasing and racing to scale
00:22:13.919 artificial intelligence int artificial
00:22:16.640 intelligence and the scaling law is a
00:22:20.039 powerful model it's an empirical law
00:22:23.000 that has been observed and demonstrated
00:22:25.400 by researchers and Industry over several
00:22:28.159 Generations ations and this the the
00:22:30.880 scale the scaling law says that the more
00:22:34.400 data you have the training data that you
00:22:37.000 have the larger model that you have and
00:22:39.440 the more compute that you apply to it
00:22:41.559 therefore the more effective or the more
00:22:44.799 capable your model will become and so
00:22:48.679 the scaling law continues what's really
00:22:51.960 amazing is that now we're moving towards
00:22:54.880 of course and the internet is producing
00:22:56.559 about twice twice the amount of data
00:22:59.520 every single year as it did last year I
00:23:01.679 think the in the next couple of years we
00:23:03.279 produce uh Humanity will produce more
00:23:05.720 data than all of humanity has ever
00:23:08.120 produced uh since the beginning and so
00:23:10.840 we're still producing a gigantic amount
00:23:13.480 of data and it's becoming more
00:23:15.440 multimodal video and images and sound
00:23:18.880 all of that data could be used to train
00:23:21.880 the fundamental knowledge the
00:23:23.520 foundational knowledge of an AI but
00:23:26.200 there are in fact two other scaling laws
00:23:30.159 that has now emerged and it's somewhat
00:23:32.760 intuitive the second scaling law is post
00:23:36.559 trining scaling law posttraining scaling
00:23:39.120 law uses Technologies techniques like
00:23:41.360 reinforcement learning human feedback
00:23:44.320 basically the AI produces and generates
00:23:47.600 answers the hum based on a human query
00:23:51.360 the human then of course gives a
00:23:53.120 feedback um it's much more complicated
00:23:55.400 than that but the reinforcement learning
00:23:56.960 system uh with a fair number of very
00:23:59.840 high quality prompts causes the AI to
00:24:03.720 refine its skills it could find tune its
00:24:07.000 skills for particular domains it could
00:24:09.080 be better at solving math problems
00:24:11.120 better at reasoning so on so forth and
00:24:13.600 so it's essentially like having a mentor
00:24:17.240 or having a coach give you feedback um
00:24:20.400 after you're done going to school and so
00:24:22.600 you you get test you get feedback you
00:24:24.520 improve yourself we also have
00:24:26.640 reinforcement learning AI feedback
00:24:29.240 and we have synthetic data generation uh
00:24:32.120 these techniques are rather uh uh Ain to
00:24:36.919 if you will uh self-practice uh you know
00:24:40.159 you know the answer to a particular
00:24:41.720 problem and uh you continue to try it
00:24:44.159 until you get it right and so an AI
00:24:46.640 could be presented with a very
00:24:48.399 complicated and difficult problem that
00:24:50.480 has that is verifiable U functionally
00:24:53.640 and has a has an answer that we
00:24:55.559 understand maybe proving a theorem maybe
00:24:57.399 solving a solving a uh geometry problem
00:25:00.799 and so these problems uh would cause the
00:25:03.240 AI to produce answers and using
00:25:05.520 reinforcement learning uh it would learn
00:25:08.000 how to improve itself that's called post
00:25:11.000 training post training requires an
00:25:12.919 enormous amount of computation but the
00:25:14.919 end result produces incredible models we
00:25:18.399 now have a third scaling law and this
00:25:21.200 third scaling law has to do with uh
00:25:24.240 what's called test time scaling test
00:25:26.360 time scaling is basically when you're
00:25:28.600 being used when you're using the AI uh
00:25:32.600 the AI has the ability to now apply a
00:25:35.760 different resource allocation instead of
00:25:37.840 improving its parameters now it's
00:25:40.399 focused on deciding how much computation
00:25:43.440 to use to produce the answers uh it
00:25:46.720 wants to
00:25:47.679 produce reasoning is a way of thinking
00:25:50.039 about this uh long thinking is a way to
00:25:52.120 think about this instead of a direct
00:25:54.720 inference or One-Shot answer you might
00:25:57.640 reason about you might break down the
00:25:59.640 problem into multiple steps you might uh
00:26:02.000 generate multiple ideas and uh evaluate
00:26:05.120 you know your AI system would evaluate
00:26:07.159 which one of the ideas that you
00:26:08.440 generated was the best one maybe it
00:26:11.080 solves the problem step by step so on so
00:26:13.320 forth and so now test time scaling has
00:26:16.360 proven to be incredibly effective you're
00:26:19.159 watching this sequence of technology and
00:26:22.159 this all of these scaling laws emerge as
00:26:24.960 we see incredible achievements from chat
00:26:28.679 GPT to 01 to 03 and now Gemini Pro all
00:26:33.520 of these systems are going through this
00:26:36.279 journey step by step by step of
00:26:38.440 pre-training to posttraining to test
00:26:41.399 time scaling well the amount of
00:26:43.399 computation that we need of course is
00:26:45.760 incredible and we would like in fact we
00:26:48.720 would like in fact that Society has the
00:26:51.039 ability to scale the amount of
00:26:52.440 computation to produce more and more
00:26:55.080 novel and better intelligence
00:26:57.679 intelligence of course is the most
00:26:59.080 valuable asset that we have and it can
00:27:01.080 be applied to solve a lot of very
00:27:02.399 challenging problems and so scaling law
00:27:06.480 it's driving enormous demand for NVIDIA
00:27:08.960 Computing it's driving an enormous
00:27:10.760 demand for this incredible chip we call
00:27:14.559 Blackwell let's take a look at Blackwell
00:27:17.720 well Blackwell is in full
00:27:21.840 production it is incredible what it
00:27:24.159 looks like so first of all there's some
00:27:27.600 uh every every single cloud service
00:27:29.480 provider now have systems up and running
00:27:31.760 uh we have systems here from about 15 uh
00:27:35.279 15 15 U uh excuse me 15 computer makers
00:27:39.960 it's being made uh about 200 different
00:27:42.840 SKS 200 different configurations they're
00:27:45.440 liquid cooled air cooled x86 Nvidia gray
00:27:48.679 CPU versions mvlink 36 by 2 MV links 72
00:27:53.919 by1 whole bunch of different types of
00:27:55.840 systems so that we can accommodate just
00:27:58.279 about every single data center in the
00:27:59.799 world well this these systems are being
00:28:03.640 currently manufactured in some 45
00:28:06.080 factories it tells you how pervasive
00:28:08.679 artificial intelligence is and how much
00:28:11.039 the industry is jumping onto artificial
00:28:13.799 intelligence in this new Computing
00:28:16.360 model well the reason why we're driving
00:28:19.880 it so hard is because we need a lot more
00:28:22.279 computation and it's very clear it's
00:28:25.120 very clear that that um
00:28:37.559 Janine you know
00:28:40.360 I it's hard to tell you don't ever want
00:28:43.840 to reach your hands into a dark
00:28:47.080 place hang a second is this a good
00:28:50.799 idea all right
00:29:08.880 wait for
00:29:11.240 it wait for
00:29:16.840 it I thought I was
00:29:23.039 worthy apparently yor didn't think I was
00:29:26.720 worthy all right
00:29:29.679 this is my show and tell this is a show
00:29:31.840 and tell so uh this mvlink system this
00:29:36.200 right here this mvlink system this is
00:29:39.720 gb200 MV link 72 it is 1 and 12
00:29:44.399 tons 600,000
00:29:47.600 Parts approximately equal to 20
00:29:51.799 cars 12 12 120 kilow
00:29:59.080 it has um a spine behind it that
00:30:02.200 connects all of these GPU
00:30:04.240 together two miles of copper
00:30:08.840 cable 5,000
00:30:11.720 cables this is being manufactured in 45
00:30:14.640 factories around the world we build them
00:30:18.200 we liquid cool them we test them we
00:30:20.960 disassemble them shiping parts to the
00:30:24.159 data centers because it's 1 and A2 tons
00:30:27.240 we reassemble it outside the data
00:30:29.039 centers and install them the
00:30:30.919 manufacturing is insane but the goal of
00:30:33.640 all of this is because the scaling laws
00:30:35.840 are driving Computing so hard that this
00:30:38.720 level of computation Blackwell over our
00:30:41.320 last generation improves the performance
00:30:44.159 per watt by a factor of four performance
00:30:47.960 per watt by a factor of four perform
00:30:50.000 performance per dollar by a factor of
00:30:52.120 three that's basically says that in one
00:30:55.760 generation we reduce the
00:30:58.840 cost of training these models by a
00:31:00.440 factor of three or if you want to
00:31:02.360 increase um the size of your model by a
00:31:04.559 factor of three it's about the same cost
00:31:06.840 but the important thing is this these
00:31:09.200 are generating tokens that are being
00:31:11.519 used by all of us when we use Chad GPT
00:31:14.519 or when we use Gemini use our phones in
00:31:16.360 the future just about all of these
00:31:18.000 applications are going to be consuming
00:31:19.919 these AI tokens and these AI tokens are
00:31:22.440 being generated by these
00:31:24.159 systems and every single data center is
00:31:26.919 limited by power
00:31:28.600 and so if the perf per watt of Blackwell
00:31:31.799 is four
00:31:33.519 times our last
00:31:36.000 generation then the revenue that could
00:31:38.440 be generated the amount of business that
00:31:40.120 can be generated in the data center is
00:31:41.519 increased by a factor of four and so
00:31:43.799 these AI Factory systems really are
00:31:46.480 factories today now the goal of all of
00:31:48.799 this is to so that we can create one
00:31:51.440 giant chip the amount of computation we
00:31:54.120 need is really quite incredible and this
00:31:56.360 is basically one giant chip if we would
00:31:58.760 have had to build a chip one here we go
00:32:02.279 sorry
00:32:03.679 guys you see that that's
00:32:06.279 cool look at that disco lights in
00:32:11.200 here right if we had to build this as
00:32:14.120 one chip obviously this would be the
00:32:15.799 size of the wafer but this doesn't
00:32:17.720 include the impact of yield it would
00:32:19.639 have to be probably three or four times
00:32:21.240 the size but what we basically have here
00:32:23.960 is 72 Blackwell gpus or 144 dieses this
00:32:28.279 one chip here is 1.4 exop flops the
00:32:32.279 world's largest supercomputer fastest
00:32:34.279 supercomputer only recently this entire
00:32:37.080 room supercomputer only recently
00:32:38.960 achieved an exf flop plus this is 1.4
00:32:42.399 exf flops of AI floating Point
00:32:44.919 performance it has 14 terabytes of
00:32:47.559 memory but here's the amazing thing the
00:32:49.320 memory bandwidth is 1.2 petabytes per
00:32:52.559 second that's basically basically the
00:32:56.320 entire internet traffic that's happening
00:32:59.720 right
00:33:01.080 now the entire world's internet traffic
00:33:04.559 is being processed across these chips
00:33:08.279 okay and we have um 103 130 trillion
00:33:12.720 transistors in total
00:33:15.200 2592 CPU
00:33:17.440 cores whole bunch of networking and so
00:33:20.919 these I wish I could do this I don't
00:33:22.799 think I will so these are the black
00:33:25.919 Wells these are our
00:33:29.240 connectx networking chips these are the
00:33:32.440 mvy link and we're trying to pretend
00:33:34.559 about the Envy the the Envy Ling spine
00:33:37.559 but that's not possible okay and these
00:33:40.760 are all of the hbm memories 12 ter 14
00:33:44.120 terabytes of hbm memory this is what
00:33:46.600 we're trying to do and this is the
00:33:47.880 miracle this is the miracle of the
00:33:49.960 Blackwell system the blackwall dies
00:33:52.440 right here it is the largest single chip
00:33:54.960 the world's ever made but yet the
00:33:57.360 miracle is really in addition to that
00:34:01.120 this is uh the grace black wall system
00:34:03.440 well the goal of all of this of course
00:34:05.480 is so that we can thank you
00:34:10.520 thanks boy is there a chair I could sit
00:34:12.719 down for a
00:34:25.760 second can I have a m AO
00:34:39.239 Ultra how is it possible that we're in
00:34:42.800 the mobe ultra
00:34:46.960 Stadium it's like coming to Nvidia and
00:34:49.199 we don't have a GPU for
00:34:54.679 you so so we need an enormous the
00:34:57.880 computation because we want to train
00:34:59.480 larger and larger models and these
00:35:02.079 inferences these inferences used to be
00:35:04.599 one inference but in the future the AI
00:35:06.920 is going to be talking to itself it's
00:35:08.160 going to be thinking it's going to be
00:35:10.119 internally reflecting processing so
00:35:12.800 today when the tokens are being
00:35:14.800 generated at you so long as it's coming
00:35:17.320 out at 20 or 30 tokens per second it's
00:35:20.839 basically as fast as anybody can read
00:35:22.760 however in the future and right now with
00:35:25.599 uh gp1 you know with the new the pre
00:35:29.560 Gemini Pro and the new GP the the 0103
00:35:32.520 models they're talking to themselves we
00:35:34.880 reflecting they thinking and so as you
00:35:37.640 can imagine the rate at which the tokens
00:35:40.160 could be ingested is incredibly high and
00:35:43.079 so we need the token rates the token
00:35:44.839 generation rates to go way up and we
00:35:47.599 also have to drive the cost way down
00:35:49.640 simultaneously so that the C the quality
00:35:52.079 of service can be extraordinary the cost
00:35:54.480 to customers can continue to be low and
00:35:57.280 uh will continue to scale and so that's
00:35:59.359 the fundamental purpose the reason why
00:36:01.280 we created MV link well one of the most
00:36:04.359 important things that's happening in the
00:36:05.520 world of Enterprise is a Genentech AI a
00:36:08.280 Genentech AI basically is a perfect
00:36:10.839 example of test time scaling it's a AI
00:36:13.760 is a system of models some of it is
00:36:16.440 understanding interacting with the
00:36:18.200 customer interacting with the user some
00:36:20.040 of it is maybe retrieving information
00:36:22.520 retrieving information from Storage a
00:36:24.920 semantic AI system like a rag uh maybe
00:36:28.000 it's going on to to the internet uh
00:36:30.200 maybe it's uh studying a PDF file and so
00:36:33.400 it might be using tools it might be
00:36:34.720 using a calculator and it might be using
00:36:36.880 a generative AI to uh generate uh charts
00:36:39.880 and such and it's iter it's taking the
00:36:42.400 the problem you gave it breaking it down
00:36:44.000 step by step and it's iterating through
00:36:45.839 all these different models well in order
00:36:48.160 to respond to a customer in the future
00:36:50.119 in order for AI to respond it used to be
00:36:52.839 ask a question answer start spewing out
00:36:55.160 in the future you ask a question a whole
00:36:57.280 bunch bu of models are going to be
00:36:58.319 working in the background and so test
00:37:01.280 time scaling the amount of computation
00:37:03.839 used for inferencing is going to go
00:37:06.079 through the roof it's going to go
00:37:07.920 through the roof because we want better
00:37:09.160 and better answers well to help the the
00:37:12.200 industry build agentic AI our our go to
00:37:15.119 market is not direct to Enterprise
00:37:16.839 customers our go to market is is we work
00:37:19.480 with software developers in the it
00:37:21.640 ecosystem to integrate our technology to
00:37:24.880 make possible new capabilities just like
00:37:27.240 we did did with Cuda libraries we now
00:37:29.880 want to do that with AI libraries and
00:37:33.720 just as the Computing model of the past
00:37:36.119 has apis that are uh doing computer
00:37:38.839 Graphics or doing linear algebra or
00:37:41.119 doing fluid dynamics in the future on
00:37:43.480 top of those acceleration libraries C
00:37:46.880 acceleration libraries will have ai
00:37:49.160 libraries we've created three things for
00:37:52.200 helping the ecosystem build agentic AI
00:37:54.839 Nvidia Nims which are essentially AI
00:37:58.280 microservices all packaged up it takes
00:38:00.800 all of this really complicated Cuda
00:38:02.680 software Cuda
00:38:04.560 DNN cutless or tensor rtlm or Triton or
00:38:09.839 all of these different really
00:38:11.400 complicated software and the model
00:38:13.240 itself we package it up we optimize it
00:38:15.839 we put it into a container and you could
00:38:17.680 take it wherever you like and so we have
00:38:20.040 models for vision for understanding
00:38:21.960 languages for speech for animation for
00:38:24.880 digital biology and we have some new new
00:38:28.000 exciting models coming for physical Ai
00:38:30.200 and these AI models run in every single
00:38:33.160 Cloud because nvidia's gpus are now
00:38:35.119 available in every single Cloud it's
00:38:36.760 available in every single OEM so you
00:38:38.560 could literally take these models
00:38:40.319 integrate it into your software packages
00:38:42.960 create AI agents that run on Cadence or
00:38:46.680 they might be S uh service now agents or
00:38:49.839 they might be sap agents and they could
00:38:52.319 deploy it to their customers and run it
00:38:54.040 wherever the customers want to run the
00:38:55.520 software the next layer is what we call
00:38:57.680 Nvidia Nemo Nemo is
00:39:02.040 essentially a digital employee
00:39:06.040 onboarding and training evaluation
00:39:09.960 system in the future these AI agents are
00:39:13.760 essentially digital Workforce that are
00:39:16.280 working alongside your employees um
00:39:18.560 working Al doing things for you on your
00:39:20.839 behalf and so the way that you would
00:39:23.599 bring these specialized agents into your
00:39:26.400 these special agents into your company
00:39:28.920 is to onboard them just like you onboard
00:39:31.200 an employee and so we have different
00:39:33.400 libraries that helps uh these AI agents
00:39:36.280 be uh trained for the type of you know
00:39:39.680 language in your company maybe the
00:39:41.359 vocabulary is unique to your company the
00:39:43.440 business process is different the way
00:39:45.280 you work is different so you would give
00:39:46.920 them examples of what the work product
00:39:49.160 should look like and they would try to
00:39:50.760 generate and you would give a feedback
00:39:52.839 and then you would evaluate them so on
00:39:54.920 so forth and so that uh and you would
00:39:57.400 guardrail them you say these are the
00:39:58.680 things that you're not allowed to do
00:39:59.920 these are things you're not allowed to
00:40:01.040 say this and and we even give them
00:40:03.520 access to certain information okay so
00:40:06.359 that entire pipeline a digital employee
00:40:09.599 pipeline is called Nemo in a lot of ways
00:40:13.920 the IT department of every company is
00:40:16.160 going to be the HR department of AI
00:40:18.520 agents in the
00:40:19.640 future today they manage and maintain a
00:40:23.240 bunch of software from uh from the IT
00:40:25.599 industry in the future they will Main
00:40:27.319 maintain you know nurture onboard and
00:40:31.079 improve a whole bunch of digital agents
00:40:33.319 and provision them to the companies to
00:40:34.920 use okay and so your H your it
00:40:37.680 department is going to become kind of
00:40:39.000 like AI agent HR and on top of that we
00:40:42.839 provide a whole bunch of blueprints that
00:40:45.359 our ecosystem could could uh take
00:40:47.640 advantage of all of this is completely
00:40:49.319 open source and so you could take take
00:40:51.400 it and uh modify the blueprints we have
00:40:53.760 blueprints for all kinds of different
00:40:55.240 different types of Agents well today
00:40:57.040 we're also announcing that we're doing
00:40:58.960 something that's really cool and I think
00:41:00.800 really clever we're announcing a whole
00:41:03.520 family of models that are based off of
00:41:06.560 llama the Nvidia llama neotron language
00:41:10.640 Foundation models llama 3.1 is a
00:41:14.760 complete
00:41:16.599 phenomenon the download of llama 3.1
00:41:19.480 from meta 350 650,000 times something
00:41:23.680 like that it has
00:41:25.920 been der red and turned into other
00:41:29.280 models uh about 60,000 other different
00:41:32.200 models it it is singularly the reason
00:41:35.160 why just about every single Enterprise
00:41:36.599 and every single industry has been
00:41:38.400 activated to start working on AI well
00:41:40.720 the thing that we did was we realized
00:41:42.960 that the Llama models really could be
00:41:45.359 better fine-tuned for Enterprise use and
00:41:48.560 so we fine-tune them using our expertise
00:41:50.560 and our capabilities and we turn them
00:41:52.640 into the Llama neotron Suite of open
00:41:56.280 models there are small ones that
00:41:59.160 interact in uh very very fast response
00:42:02.079 time extremely small uh they're uh sup
00:42:05.640 what we call Super llama neotron supers
00:42:08.880 they're basically your mainstream
00:42:10.560 versions of your models or your Ultra
00:42:13.000 model the ultra model could be used uh
00:42:15.520 to be a teacher model for a whole bunch
00:42:17.960 of other models it could be a reward
00:42:20.079 model evaluator uh a judge for other
00:42:23.359 models to create answers and decide
00:42:25.680 whether it's a good answer or not
00:42:27.680 give basically give feedback to other
00:42:29.359 models it could be distilled in a lot of
00:42:31.160 different ways basically a teacher model
00:42:33.319 a knowledge distillation uh uh model
00:42:36.760 very large very capable and so all of
00:42:39.200 this is now available online well these
00:42:43.000 models are incredible it's a a number
00:42:46.359 one in leaderboards for chat leaderboard
00:42:49.119 for instruction uh lead leaderboard for
00:42:53.160 retrieval um so the different types of
00:42:55.520 functionalities necessary that are used
00:42:57.800 in AI agents around the world uh these
00:43:00.040 are going to be incredible models for
00:43:02.119 you we're also working with uh the
00:43:04.760 ecosystem these Tech all of our Nvidia
00:43:07.240 AI Technologies are integrated into uh
00:43:10.280 uh the it in Industry uh we have great
00:43:13.000 partners and really great work being
00:43:14.680 done at service now at sap at Seaman uh
00:43:18.319 for industrial AI uh Cadence is during
00:43:21.359 great work synopsis doing great work I'm
00:43:23.480 really proud of the work that we do with
00:43:25.200 perplexity as you know they
00:43:26.440 revolutionize search yeah really
00:43:28.800 fantastic stuff uh codium uh every every
00:43:32.079 software engineer in the world this is
00:43:33.559 going to be the next giant AI
00:43:36.760 application next giant AI service period
00:43:41.000 is software coding 30 million software
00:43:43.760 Engineers around the world everybody is
00:43:46.160 going to have a software assistant uh
00:43:48.359 helping them code uh if if um if not
00:43:51.400 obviously you're just you're going to be
00:43:53.280 way less productive and create lesser
00:43:55.440 good code and so this is 30 million
00:43:58.200 there's a billion knowledge workers in
00:44:00.520 the world it is very very clear AI
00:44:03.319 agents is probably the next robotics
00:44:06.160 industry and likely to be a
00:44:07.800 multi-trillion dollar opportunity well
00:44:10.240 let me show you some of the uh
00:44:12.599 blueprints that we've created and some
00:44:14.800 of the work that we've done with our
00:44:15.880 partners uh with these AI
00:44:21.920 agents AI agents are the new digital
00:44:25.280 Workforce working for and with
00:44:28.280 us AI agents are a system of models that
00:44:32.520 reason about a mission break it down
00:44:34.599 into tasks and retrieve data or use
00:44:37.440 tools to generate a quality
00:44:40.160 response nvidia's agentic AI building
00:44:43.079 blocks Nim pre-trained models and Nemo
00:44:46.240 framework let organizations easily
00:44:48.599 develop AI agents and deploy them
00:44:51.400 anywhere we will onboard and train our
00:44:54.079 agentic workforces on our company's
00:44:56.400 methods like we do for
00:44:58.559 employees AI agents are domain specific
00:45:02.119 task experts let me show you four
00:45:04.839 examples for the billions of knowledge
00:45:07.160 workers and students AI research
00:45:09.680 assistant agents ingest complex
00:45:12.040 documents like lectures journals
00:45:14.800 Financial results and generate
00:45:16.920 interactive podcasts for easy learning
00:45:19.880 by combining a unet regression model
00:45:21.920 with a diffusion model cordi can
00:45:24.160 downscale global weather forecasts down
00:45:26.200 from 25 km to 2
00:45:28.880 km developers like at Nvidia manage
00:45:32.359 software security AI agents that
00:45:34.800 continuously scan software for
00:45:37.119 vulnerabilities alerting developers to
00:45:39.680 what action is
00:45:41.680 needed Virtual Lab AI agents help
00:45:45.240 researchers design and Screen billions
00:45:47.240 of compounds to find promising drug
00:45:49.920 candidates faster than
00:45:52.200 ever Nvidia analytics AI agents built on
00:45:56.000 an Nvidia metr blueprint including
00:45:58.599 Nvidia Cosmos nimron Vision language
00:46:01.240 models llama neaton llms and Nemo
00:46:05.480 retriever Metropolis agents analyze
00:46:08.520 content from the billions of cameras
00:46:11.119 generating 100,000 pedes of video per
00:46:14.280 day they enable interactive search
00:46:17.599 summarization and automated
00:46:20.680 reporting and help monitor traffic flows
00:46:23.960 flagging congestion or danger
00:46:28.240 in industrial facilities they monitor
00:46:31.040 processes and generate recommendations
00:46:33.400 or
00:46:34.960 Improvement Metropolis agents centralize
00:46:38.040 data from hundreds of cameras and can
00:46:40.359 reroute workers or robots when incidents
00:46:43.800 occur the age of agentic AI is here for
00:46:48.000 every
00:46:52.319 organization okay
00:46:57.599 that was the first pitch at a baseball
00:47:00.520 that was not generated I just felt that
00:47:03.079 none of you were
00:47:05.200 impressed okay so ai ai was was created
00:47:09.480 in the cloud and for the cloud AI is
00:47:12.720 creating the cloud for the cloud and for
00:47:15.440 uh enjoying AI on on phones of course
00:47:18.040 it's perfect um very very soon we're
00:47:21.040 going to have a continuous AI that's
00:47:23.040 going to be with you and when you use
00:47:25.079 those metag glasses you could of course
00:47:27.839 uh point at something look at something
00:47:29.520 and and ask it you know whatever
00:47:31.160 information you want and so AI is is
00:47:34.119 perfect in the CL was creating the cloud
00:47:35.880 is perfect in the cloud however we would
00:47:38.040 love to be able to take that AI
00:47:40.200 everywhere I've mentioned already that
00:47:41.800 you could take Nvidia AI to any Cloud
00:47:44.280 but you could also put it inside your
00:47:45.680 company but the thing that we want to do
00:47:47.359 more than anything is put it on our PC
00:47:49.119 as well and so as you know Windows 95
00:47:53.119 revolutionized the computer industry it
00:47:55.160 made possible this new Suite of
00:47:57.319 multimedia services and it change the
00:47:59.280 way that applications was created
00:48:01.319 forever um Windows 95 this this model of
00:48:05.720 computing of course is not perfect for
00:48:08.040 AI and so the thing that we would like
00:48:10.280 to do is we would like to have in the
00:48:13.000 future your AI basically become your AI
00:48:15.680 assistant and instead of instead of just
00:48:18.559 the the 3D apis and the sound apis and
00:48:21.119 the video API you would have generative
00:48:23.720 apis generative apis for 3D and
00:48:25.960 generative apis for language and
00:48:27.400 generative AI for sound and so on so
00:48:29.240 forth and we need a system that makes
00:48:32.599 that possible while leveraging the
00:48:35.599 massive investment that's in the cloud
00:48:38.119 there's no way that we could the world
00:48:40.160 can create yet another way of
00:48:41.880 programming AI models it's just not
00:48:44.160 going to happen and so if we could
00:48:46.440 figure out a way to make Windows
00:48:50.160 PC a worldclass
00:48:52.640 aipc um it would be completely awesome
00:48:55.160 and it turns out the answer is Windows
00:48:58.000 it's Windows wsl2 Windows wsl2 Windows
00:49:03.480 wsl2 basically it's two operating
00:49:06.000 systems within one it works perfectly
00:49:09.200 it's developed for developers and it's
00:49:11.079 developed uh uh so that you can have
00:49:13.720 access to Bare Metal it's been wsl2 has
00:49:16.599 been
00:49:17.680 optimized optimized for cloud native
00:49:20.839 applications it is optimized for and
00:49:23.480 very importantly it's been optimized for
00:49:25.720 Cuda and so wsl2 supports Cuda perfectly
00:49:29.640 out of the box as a
00:49:31.799 result everything that I showed you with
00:49:36.559 Nvidia Nims Nvidia Nemo the blueprints
00:49:41.760 that we develop that are going to be up
00:49:43.680 in ai. nvidia.com so long as the
00:49:47.240 computer fits it so long as you can fit
00:49:50.079 that model and we're going to have many
00:49:51.880 models that that fit whether it's Vision
00:49:54.000 models or language models or speech
00:49:55.480 models or these animation human digital
00:49:58.680 human models all kinds of different
00:50:01.280 different types of models are going to
00:50:02.400 be perfect for your PC and it would you
00:50:06.000 download it and it should just run and
00:50:08.319 so our focus is to turn Windows wsl2
00:50:12.960 Windows PC into a Target first class
00:50:16.720 platform that we will support and
00:50:19.040 maintain for as long as we shall live
00:50:21.000 and so this is an incredible thing for
00:50:23.520 engineers and developers everywhere let
00:50:25.520 let me show you something that we can do
00:50:27.040 with that this is one of the examples of
00:50:28.440 a blueprint we just made for
00:50:31.880 you generative AI synthesizes amazing
00:50:35.200 images from Simple Text prompts yet
00:50:38.319 image composition can be challenging to
00:50:40.319 control using only words with Nvidia Nim
00:50:43.640 microservices creators can use Simple 3D
00:50:46.920 objects to guide AI image generation
00:50:49.880 let's see how a concept artist can use
00:50:52.200 this technology to develop the look of a
00:50:54.799 scene they start by laying out 3D assets
00:50:58.359 created by hand or generated with AI
00:51:01.280 then use an image generation Nim such as
00:51:04.000 flux to create a visual that adheres to
00:51:06.720 the 3D
00:51:07.920 scene add or move objects to refine the
00:51:13.119 composition change camera angles to
00:51:15.880 frame the perfect
00:51:17.599 shot or reimagine the whole scene with a
00:51:20.440 new
00:51:24.200 prompt assisted by generative AI and
00:51:26.799 Nvidia Nim and artists can quickly
00:51:29.160 realize their
00:51:33.040 Vision Nvidia AI for your
00:51:37.319 PCS hundreds of millions of PCS in the
00:51:40.119 world with Windows and so we could get
00:51:42.720 them ready for AI uh oems all the PC
00:51:45.839 oems we work with just basically all of
00:51:47.640 the world's leading PC oems are going to
00:51:49.559 get their PCS ready for this stack and
00:51:52.240 so aips are coming to a home near you
00:52:02.000 Linux is
00:52:08.040 good okay let's talk about physical
00:52:12.240 AI speaking of Linux let's talk about
00:52:14.680 physical
00:52:16.440 AI So Physical AI imagine
00:52:22.280 imagine whereas your large language
00:52:25.200 model you give it your your context your
00:52:30.040 prompt on the left and it generates
00:52:34.480 tokens one at a time to produce the
00:52:37.960 output that's basically how it works the
00:52:40.599 amazing thing is this model in the
00:52:42.280 middle is quite large has billions of
00:52:45.200 parameters the context length is
00:52:47.640 incredibly large because you might
00:52:49.920 decide to load in a PDF in my case I
00:52:51.920 might load in several PDFs before I ask
00:52:54.599 it a question those PDFs are turned into
00:52:57.520 tokens the attention the basic attention
00:53:00.319 characteristic of a transformer has
00:53:02.880 every single token find its relationship
00:53:05.079 and relevance against every other token
00:53:08.359 so you could have hundreds of thousands
00:53:10.799 of tokens and the computational load
00:53:14.079 increases quadratically and it does this
00:53:17.680 that all of the parameters all of the
00:53:19.400 input sequence process it through every
00:53:21.440 single layer of the Transformer and it
00:53:23.240 produces one token that's the reason why
00:53:25.720 we needed blackw
00:53:27.240 and then the next token is produced when
00:53:30.000 the current token is done it puts the
00:53:32.240 current token into the input sequence
00:53:34.960 and takes that whole thing and generates
00:53:36.960 the next token it does it one at a time
00:53:39.680 this is the Transformer model it's the
00:53:41.960 reason why it is so so incredibly
00:53:44.640 effective computationally demanding What
00:53:47.720 If instead of PDFs it's your surrounding
00:53:51.200 and what if instead of the prompt a
00:53:53.599 question it's a request go over there
00:53:55.880 and pick up that that you know that box
00:53:58.160 and bring it back and instead of what is
00:54:00.760 produced in tokens its text it produces
00:54:04.280 action
00:54:05.319 tokens well that I just described is a
00:54:09.480 very sensible thing for the future of
00:54:11.559 Robotics and the technology is right
00:54:13.799 around the corner but what we need to do
00:54:16.240 is we need to create the effective
00:54:18.440 effectively the world
00:54:21.000 model of you know as opposed to GPT
00:54:24.760 which is a language model and this World
00:54:26.640 model has to understand the language of
00:54:28.920 the world it has to understand physical
00:54:31.559 Dynamics things like gravity and
00:54:34.559 friction and inertia it has to
00:54:36.880 understand geometric and spatial
00:54:38.680 relationships it has to understand cause
00:54:40.760 and effect if you drop something a fall
00:54:42.640 to the ground if you you know poke at it
00:54:44.680 it tips over it has to understand object
00:54:48.359 permanence if you roll a ball over the
00:54:50.799 kitchen counter when it goes off the
00:54:52.280 other side the ball didn't leave into
00:54:54.400 another quantum universe that that's
00:54:56.559 still there and so all of these types of
00:54:59.760 understanding is intuitive understanding
00:55:01.400 that we know that most models today have
00:55:04.440 a very hard time with and so we would
00:55:06.920 like to create a world we need a world
00:55:09.160 Foundation model today we're announcing
00:55:11.359 a very big thing we're announcing Nvidia
00:55:14.960 Cosmos a world Foundation model that is
00:55:18.960 designed that was created to understand
00:55:21.559 the physical world and the only way for
00:55:23.720 you to really understand this is to see
00:55:25.680 it let's
00:55:32.720 flip the next Frontier of AI is physical
00:55:36.280 AI model performance is directly related
00:55:39.760 to data availability but physical world
00:55:42.559 data is costly to capture curate and
00:55:46.520 label Nvidia Cosmos is a world
00:55:49.520 Foundation model development platform to
00:55:51.920 Advance Physical AI it includes Auto
00:55:55.240 regressive world found Foundation models
00:55:57.480 diffusion-based World Foundation models
00:56:00.119 Advanced
00:56:01.200 tokenizers and an Nvidia Cuda an AI
00:56:04.440 accelerated data
00:56:07.520 pipeline Cosmos models ingest text image
00:56:11.039 or video prompts and generate virtual
00:56:13.319 world States as
00:56:14.920 videos Cosmos Generations prioritize the
00:56:17.920 unique requirements of Av and Robotics
00:56:20.359 use cases like real world environments
00:56:23.799 lighting and object permanence
00:56:27.280 developers use Nvidia Omniverse to build
00:56:29.920 physics-based
00:56:31.160 geospatially accurate scenarios then
00:56:34.079 output Omniverse renders into Cosmos
00:56:36.920 which generates photoreal physically
00:56:39.079 based synthetic
00:56:51.200 data whether diverse
00:56:54.240 objects or environments
00:56:58.359 conditions like weather or time of day
00:57:01.880 or Edge case
00:57:04.720 scenarios developers use Cosmos to
00:57:07.640 generate worlds for reinforcement
00:57:09.359 learning AI feedback to improve policy
00:57:13.319 models or to test and validate model
00:57:17.400 performance even across multisensor
00:57:21.640 views Cosmos can generate tokens in real
00:57:24.760 time bringing the power of foresight and
00:57:27.720 Multiverse simulation to AI models
00:57:30.880 generating every possible future to help
00:57:33.599 the model select the right
00:57:36.359 path working with the world's developer
00:57:38.960 ecosystem Nvidia is helping Advance the
00:57:41.799 next wave of physical
00:57:48.400 AI Nvidia
00:57:51.680 Cosmos Nvidia
00:57:54.039 Cosmos Nvidia Cosmos the world's first
00:57:58.000 world Foundation model it is trained on
00:58:02.079 20 million hours of video the 20 million
00:58:06.079 hours of video focuses on physical
00:58:09.440 Dynamic things so n n Dynamic nature
00:58:12.559 nature themes themes uh humans uh
00:58:15.839 walking uh hands moving uh manipulating
00:58:19.839 things uh you know things that are uh
00:58:22.720 fast camera movements it's really about
00:58:24.880 teaching the AI not about generating
00:58:27.559 creative content but teaching the AI to
00:58:30.559 understand the physical world and from
00:58:32.640 this with this physical AI there are
00:58:35.720 many Downstream things that we could uh
00:58:38.480 do as a result we could do synthetic
00:58:40.000 data generation to train uh models we
00:58:43.480 could distill it and turn it into
00:58:45.760 effectively the seed the beginnings of a
00:58:47.799 robotics model you could have it
00:58:49.559 generate multiple physically based
00:58:53.079 physically plausible uh scenarios that
00:58:56.119 the future basically do a doctor strange
00:58:58.799 um you could uh because because this
00:59:01.039 model understands the physical world of
00:59:02.640 course you saw a whole bunch of images
00:59:03.880 generated this model understanding the
00:59:05.920 physical world it also uh could do of
00:59:08.799 course captioning and so it could take
00:59:11.599 videos caption it incredibly well and
00:59:14.839 that captioning and the video could be
00:59:17.200 used to train large language models
00:59:21.680 multimodality large language models and
00:59:24.599 uh so you could use this technology to
00:59:26.920 use this Foundation model to train
00:59:28.720 robotics robots as well as larger
00:59:30.680 language models and so this is the
00:59:32.359 Nvidia Cosmos the platform has an auto
00:59:35.760 regressive model for real-time
00:59:37.160 applications has diffusion model for a
00:59:39.440 very high quality image generation it's
00:59:42.079 incredible tokenizer basically learning
00:59:44.599 the vocabulary of uh real world and a
00:59:48.200 data pipeline so that if you would like
00:59:49.839 to take all of this and then train it on
00:59:52.000 your own data this data pipeline because
00:59:54.359 there's so much data involved we've
00:59:56.319 accelerated everything end to endend for
00:59:58.000 you and so this is the world's first
01:00:00.280 data processing pipeline that's Cuda
01:00:02.440 accelerated as well as AI accelerated
01:00:04.839 all of this is part of the cosmos
01:00:06.920 platform and today we're announcing that
01:00:09.119 Cosmos is open licensed it's open
01:00:12.119 available on
01:00:19.760 GitHub we hope we hope that this moment
01:00:23.280 and there's a there's a small medium
01:00:24.799 large for uh uh very fast models um you
01:00:28.799 know mainstream models and also teacher
01:00:30.760 models basically not knowledge transfer
01:00:33.079 models Cosmo Cosmos World Foundation
01:00:36.599 model being open we really hope will do
01:00:39.640 for the world of Robotics and Industrial
01:00:41.599 AI what llama 3 has done for Enterprise
01:00:45.079 AI the magic happens when you connect
01:00:49.559 Cosmos to Omniverse and the reason
01:00:51.760 fundamentally is this Omniverse is a
01:00:56.480 physics grounded not physically grounded
01:00:59.760 but physics grounded it's algorithmic
01:01:02.400 physics principled physics simulation
01:01:05.119 grounded system it's a simulator when
01:01:08.200 you connect that to
01:01:10.200 Cosmos it provides the grounding the
01:01:13.559 ground truth that can control and to
01:01:16.559 condition the Osmos generation as a
01:01:19.440 result what comes out of Osmos is
01:01:21.240 grounded on Truth this is exactly the
01:01:23.319 same idea as connecting a large language
01:01:25.720 model model to a rag to a retrieval
01:01:28.720 augmented generation system you want to
01:01:30.880 ground the AI generation on ground truth
01:01:34.520 and so the combination of the two gives
01:01:36.920 you a
01:01:38.359 physically simulated a physically
01:01:41.720 grounded Multiverse generator and the
01:01:45.400 application the use cases are really
01:01:47.319 quite exciting and of course uh for
01:01:50.280 robotics uh for industrial applications
01:01:52.960 uh it is very very clear this Cosmos
01:01:56.039 plus
01:01:57.079 o Omniverse plus Cosmos represents the
01:02:00.799 Third computer that's necessary for
01:02:02.920 building robotic systems every robotics
01:02:05.920 company will ultimately have to build
01:02:07.839 three computers a robotics the robotics
01:02:10.319 system could be a factory the robotics
01:02:11.760 system could be a car it could be a
01:02:13.319 robot you need three fundamental
01:02:15.680 computers one computer of course to
01:02:17.559 train the AI we call the dgx computer to
01:02:21.039 train the AI another of course when
01:02:24.119 you're done to deploy the AI we call
01:02:26.640 that agx that's inside the car in the
01:02:28.760 robot or in an AMR or you know at the uh
01:02:32.079 in a in a stadium or whatever it is
01:02:34.520 these computers are at the edge and
01:02:37.200 they're autonomous but to connect the
01:02:39.559 two you need a digital twin and this is
01:02:42.119 all the simulations that you were seeing
01:02:43.920 the digital twin is where the AI that
01:02:46.440 has been trained goes to practice to be
01:02:50.279 refined to do its synthetic data
01:02:52.599 generation reinforcement learning AI
01:02:54.920 feedback such and such and so it's the
01:02:57.160 digital twin of the AI these three
01:02:59.680 computers are going to be working
01:03:01.039 interactively nvidia's strategy for uh
01:03:04.000 the industrial world and we've been
01:03:05.920 talking about this for some time is this
01:03:07.839 three computer
01:03:09.440 system you know instead of a three three
01:03:12.119 body problem we have a three Computer
01:03:14.200 Solution and so it's the Nvidia
01:03:22.960 robotics so let me give you three
01:03:25.119 examples
01:03:26.279 all right so the first example is uh uh
01:03:29.640 how we apply apply all of this to
01:03:32.960 Industrial digitalization there millions
01:03:36.240 of factories hundreds of thousands of
01:03:38.839 warehouses that's basically it's the
01:03:41.000 backbone of A50 trillion doll
01:03:43.720 manufacturing industry all of that has
01:03:46.079 to become software defined all of that
01:03:48.880 has has to have Automation in the future
01:03:51.359 and all of it will be infused with
01:03:53.000 robotics well we're partnering with Keon
01:03:56.359 the world's leading Warehouse automation
01:04:00.200 Solutions provider and Accenture the
01:04:03.279 world's largest professional services
01:04:05.319 provider and they have a big focus in
01:04:08.160 digital manufacturing and we're working
01:04:10.599 together to create something that's
01:04:12.799 really special and I'll show you that in
01:04:14.160 the second but our go to market is
01:04:16.240 essentially the same as all of the other
01:04:18.839 software uh platforms and all the
01:04:20.760 technology platforms that we have
01:04:22.400 through the uh developers and ecosystem
01:04:26.359 Partners uh and we have just just a
01:04:29.039 growing number of ecosystem Partners
01:04:31.839 connecting to Omniverse and the reason
01:04:34.039 for that is very clear everybody wants
01:04:36.279 to digitalize the future of Industries
01:04:38.520 there's so much waste so much
01:04:40.960 opportunity for Automation in that $50
01:04:43.160 trillion doar of the world's GDP so
01:04:45.440 let's take a look at that this one one p
01:04:47.760 one example that we're doing with Keon
01:04:49.520 and
01:04:52.359 Accenture Keon the supply chain solution
01:04:55.839 company Accenture a global leader in
01:04:58.960 Professional Services and Nvidia are
01:05:01.720 bringing physical AI to the $1 trillion
01:05:05.039 warehouse and Distribution Center Market
01:05:08.599 managing high- Performance Warehouse
01:05:10.559 Logistics involves navigating a complex
01:05:13.240 web of decisions influenced by
01:05:15.480 constantly shifting variables these
01:05:18.079 include daily and seasonal demand
01:05:20.200 changes space constraints Workforce
01:05:23.240 availability and the integration of of
01:05:25.839 diverse robotic and automated systems
01:05:28.920 and predicting operational kpis of a
01:05:31.760 physical Warehouse is nearly impossible
01:05:34.720 today to tackle these challenges Keon is
01:05:38.119 adopting Mega an Nvidia Omniverse
01:05:40.480 blueprint for building industrial
01:05:42.359 digital twins to test and optimize
01:05:45.079 robotic fleets first Keon's warehouse
01:05:48.520 management solution assigns tasks to the
01:05:51.319 industrial AI brains in the digital twin
01:05:54.480 such as moving a load from from a buffer
01:05:56.119 location to a shuttle storage
01:05:58.480 solution the robot's brains are in a
01:06:01.200 simulation of a physical Warehouse
01:06:03.640 digitalized into Omniverse using open
01:06:06.039 USD connectors to aggregate CAD video
01:06:09.839 and image to 3D Light Art to point cloud
01:06:13.680 and AI generated data the fleet of
01:06:16.680 robots execute tasks by perceiving and
01:06:20.079 reasoning about their Omniverse digital
01:06:22.079 twin environment planning their next
01:06:24.240 motion and acting
01:06:26.279 the robot brains can see the resulting
01:06:28.599 State through sensor simulations and
01:06:30.960 decide their next action the loop
01:06:33.400 continues while Mega precisely tracks
01:06:36.359 the state of everything in the digital
01:06:38.599 twin now Keon can simulate infinite
01:06:42.039 scenarios at scale while measuring
01:06:44.599 operational kpis such as throughput
01:06:48.039 efficiency and utilization all before
01:06:50.960 deploying changes to the physical
01:06:53.599 Warehouse together with Nvidia
01:06:56.119 Keon and Accenture are Reinventing
01:06:58.720 industrial
01:07:00.839 autonomy in the future is that that's
01:07:03.279 incredible everything is in
01:07:05.440 simulation in the future in the future
01:07:09.680 every Factory will have a digital twin
01:07:12.720 and that digital twin operates exactly
01:07:14.920 like the real factory and in fact you
01:07:17.920 could use Omniverse with Cosmos to
01:07:20.440 generate a whole bunch of future
01:07:22.119 scenarios and you pick then an AI
01:07:24.960 decides which which one of the scenarios
01:07:26.319 are the most optimal for whatever kpis
01:07:28.920 and that becomes the programming
01:07:30.839 constraints the program if you will the
01:07:33.039 AI that will be uh deployed into the
01:07:35.119 real factories the next example
01:07:37.039 autonomous vehicles the AV revolution
01:07:39.799 has arrived after so many years with weo
01:07:43.799 success and Tesla's success it is very
01:07:46.559 very clear autonomous vehicles has
01:07:48.920 finally arrived well our offering to
01:07:51.640 this industry is the three computers the
01:07:54.279 training systems the training the AIS
01:07:56.480 the simulation systemss and and the and
01:07:58.880 the synthetic data generation systems
01:08:00.640 Omniverse and now Cosmos and also the
01:08:03.319 computer that's inside the car each car
01:08:06.359 company might might work with us in a
01:08:08.039 different way use one or two or three of
01:08:10.039 the computers we're working with just
01:08:12.079 about every major car company around the
01:08:14.160 world whmo and zuk and Tesla of course
01:08:17.198 in their data center byd the largest uh
01:08:20.198 EV company in the world jlr has got a
01:08:22.238 really cool car coming Mercedes because
01:08:24.359 a fleet of cars coming with Nvidia
01:08:26.279 starting with this starting this year
01:08:27.679 going to production and I'm super super
01:08:30.238 pleased to announce that today Toyota
01:08:33.839 and Nvidia are going to partner together
01:08:35.399 to create their next Generation
01:08:43.920 AVS just so many so many cool companies
01:08:47.158 uh lucid and rivan and Shi and of course
01:08:50.960 uh Volvo just so many different
01:08:52.759 companies Wabi is uh building uh
01:08:54.880 self-driving trucks Aurora we announced
01:08:57.839 this week also that Aurora is going to
01:08:59.319 use Nvidia to build self-driving trucks
01:09:02.600 autonomous 100 million cars build each
01:09:05.120 year a billion cars vehicles on a road
01:09:08.479 all over the world a trillion miles that
01:09:10.560 are driven around the world each year
01:09:13.319 that's all going to be either highly
01:09:15.719 autonomous or you know fully autonomous
01:09:18.319 coming up and so this is going to be a
01:09:20.120 very L very large industry I predict
01:09:22.479 that this will likely be the first
01:09:24.319 multi-trillion dollar
01:09:26.080 robotics industry this IND this business
01:09:28.679 for us um notice in just just a few of
01:09:33.040 these cars that are starting to ramp
01:09:34.679 into the world uh our business is
01:09:36.679 already $4 billion and this year
01:09:39.040 probably on a run rate of about $5
01:09:40.399 billion so really significant business
01:09:42.560 already this is going to be very large
01:09:44.399 well today we're announcing that our
01:09:46.479 next generation processor for the car
01:09:49.439 our next generation computer for the car
01:09:51.080 is called Thor I have one right here
01:09:53.120 hang on a second
01:09:57.120 okay this is
01:09:58.480 Thor this is
01:10:01.120 Thor this is this is a robotics
01:10:05.719 computer this is a robotics computer
01:10:08.120 takes sensors and just a Madness amount
01:10:11.440 of sensor information process it you
01:10:15.360 know een teed cameras high resolution
01:10:20.040 Radars Liars they're all coming into
01:10:22.280 this chip and this chip has to process
01:10:24.679 all that sensor turn them into tokens
01:10:27.360 put them into a Transformer and predict
01:10:30.360 the next PATH and this AV computer is
01:10:34.400 now in full production Thor is 20 times
01:10:38.600 the processing capability of our last
01:10:40.520 generation Orin which is really the
01:10:42.440 standard of autonomous vehicles today
01:10:44.840 and so this is just really quite quite
01:10:47.000 incredible Thor is in full production
01:10:49.080 this robotics processor by the way also
01:10:51.199 goes into a full robot and so it could
01:10:53.360 be an AMR it could be a human or robot
01:10:56.679 could be the brain it could be the
01:10:58.600 manipulator this Rob this processor
01:11:00.920 basically is a universal robotics
01:11:04.520 computer the second part of our drive
01:11:08.000 system that I'm incredibly proud of is
01:11:10.280 the dedication to safety Drive OS I'm
01:11:14.480 pleased to announce is now the first
01:11:17.080 softwar defined programmable AI computer
01:11:21.239 that has been certified up to asold D
01:11:24.920 which is the highest standard of
01:11:27.760 functional safety for automobiles the
01:11:30.840 only and the highest and so I'm really
01:11:33.320 really proud of this asold ISO
01:11:36.440 26262 it is um the work of some 15,000
01:11:40.560 engineering years this is just
01:11:43.040 extraordinary work and as a result of
01:11:45.360 that Cuda is now a functional safe
01:11:49.159 computer and so if you're building a
01:11:51.040 robot Nvidia Cuda y
01:11:58.239 okay so so now I wanted to I told you I
01:12:00.440 was going to show you what would we use
01:12:03.159 Omniverse and Cosmos to do in the
01:12:06.480 context of self-driving cars and you
01:12:09.719 know today instead of showing you a
01:12:11.320 whole bunch of uh uh videos of of cars
01:12:14.320 driving on the road I'll show you some
01:12:16.280 of that too um but I want to show you
01:12:19.000 how we use the car to reconstruct
01:12:22.280 digital twins automatically using Ai and
01:12:25.880 use that capability to train future am
01:12:29.320 models okay let's play
01:12:34.000 it the autonomous vehicle Revolution is
01:12:37.400 here building autonomous vehicles like
01:12:40.719 all robots requires three computers
01:12:44.280 Nvidia dgx to train AI models Omniverse
01:12:48.040 to test drive and generate synthetic
01:12:50.199 data and drive agx a supercomputer in
01:12:54.159 the car
01:12:55.719 building safe autonomous vehicles means
01:12:58.199 addressing Edge scenarios but real world
01:13:01.440 data is limited so synthetic data is
01:13:04.719 essential for
01:13:06.480 training the autonomous vehicle data
01:13:09.040 Factory powered by Nvidia Omniverse AI
01:13:12.320 models and Cosmos generates synthetic
01:13:15.639 driving scenarios that enhance training
01:13:18.000 data by orders of
01:13:20.679 magnitude first omnimap fuses map and
01:13:24.360 geospatial data to construct drivable 3D
01:13:31.239 environments driving scenario variations
01:13:34.239 can be generated from replay Drive logs
01:13:36.840 or AI traffic
01:13:39.320 generators next a neural reconstruction
01:13:42.239 engine uses autonomous vehicle sensor
01:13:45.080 logs to create High Fidelity 4D
01:13:48.600 simulation
01:13:49.880 environments it replays previous drives
01:13:52.320 in 3D and generates scenario Vari ations
01:13:55.840 to amplify training
01:13:57.760 data finally edify 3DS automatically
01:14:01.600 searches through existing asset
01:14:04.400 libraries or generates new assets to
01:14:07.960 create Sim ready
01:14:12.000 scenes the Omniverse scenarios are used
01:14:15.000 to condition Cosmos to generate massive
01:14:18.000 amounts of photo realistic data reducing
01:14:20.800 the Sim toore
01:14:22.600 Gap and with text prompts generate near
01:14:26.560 infinite variations of the driving
01:14:30.280 scenario with Cosmos neotron video
01:14:33.199 search the massively scaled synthetic
01:14:36.120 data set combined with recorded drives
01:14:39.600 can be curated to train
01:14:43.199 models nvidia's AI data Factory scales
01:14:47.120 hundreds of drives into billions of
01:14:49.440 effective miles setting the standard for
01:14:52.920 safe and advanced autonomous driving
01:14:59.400 is that incredible
01:15:03.199 we take take thousands of drives and
01:15:08.120 turn them into billions of miles we are
01:15:11.199 going to have mountains of training data
01:15:14.120 for autonomous vehicles of course we
01:15:16.239 still need actual cars on the road of
01:15:18.960 course we will continuously collect data
01:15:21.199 for as long as we shall live however
01:15:23.360 synthetic data generation using this
01:15:26.440 Multiverse physically based physically
01:15:29.320 grounded capability so that we generate
01:15:32.320 data for training AIS that are
01:15:34.560 physically grounded and accurate and or
01:15:36.520 plausible so that we could have an
01:15:38.600 enormous amount of data to train with
01:15:40.320 the AV industry is here uh this is an
01:15:43.159 incredibly exciting time super super
01:15:45.440 super uh uh excited about the next
01:15:47.639 several years I think you're going to
01:15:48.719 see just as computer Graphics was
01:15:51.320 revolutionized such incredible pace
01:15:53.480 you're going to see the pace of Av
01:15:55.639 development increasing tremendously over
01:15:57.880 the next several
01:16:08.880 years I I think I think
01:16:13.159 um I I think the next part is is
01:16:17.560 robotics so um
01:16:26.840 human
01:16:31.040 robots my
01:16:38.080 friends the chat GPT moment for General
01:16:42.199 robotics is just around the corner and
01:16:44.880 in fact all of the enabling technologies
01:16:46.800 that I've been talking about is going to
01:16:50.400 make it possible for us in the next
01:16:52.360 several years to see very rapid break
01:16:54.880 breakthroughs surprising breakthroughs
01:16:56.400 in in general robotics now the reason
01:16:58.520 why General robotics is so important is
01:17:01.040 whereas robots with tracks and wheels
01:17:03.639 require special environments to
01:17:05.760 accommodate them there are three
01:17:09.159 robots three robots in the world that we
01:17:11.639 can make that require no green
01:17:15.080 fields Brown field adaptation is perfect
01:17:19.040 if we if we could possibly build these
01:17:20.920 amazing robots we could deploy them in
01:17:23.719 exactly the world that we've built for
01:17:25.400 ourselves these three robots are one
01:17:29.199 agentic robots agentic AI because you
01:17:33.120 know they're information workers so long
01:17:34.560 as they could accommodate uh the
01:17:36.280 computers that we have in our offices is
01:17:37.880 going to be great number two
01:17:40.400 self-driving cars and the reason for
01:17:42.239 that is we spent 100 plus years building
01:17:44.639 roads and cities and then number three
01:17:47.679 human or robots if we have the
01:17:50.040 technology to solve these three this
01:17:53.000 will be the largest technology industry
01:17:54.840 IND the world's ever seen and so we
01:17:58.400 think that robotics era is just around
01:18:01.520 the corner the critical capability is
01:18:04.880 how to train these robots in the case of
01:18:07.520 human or
01:18:08.760 robots the imitation information is
01:18:12.239 rather hard to collect and the reason
01:18:14.280 for that is uh in the case of car you
01:18:16.400 just drive it we're driving cars all the
01:18:17.960 time in the case of these human robots
01:18:20.880 the imitation information the the human
01:18:23.280 demonstration is rather laborious is to
01:18:25.159 do and so we need to come up with a
01:18:27.159 clever way to take hundreds of
01:18:30.159 demonstrations thousands of human
01:18:32.400 demonstrations and somehow use
01:18:35.120 artificial intelligence and
01:18:37.320 Omniverse to synthetically
01:18:40.280 generate
01:18:42.239 millions
01:18:44.480 of
01:18:46.280 synthetically generated motions and from
01:18:49.560 those motions the AI can learn uh how to
01:18:52.719 perform a task let me show you how
01:18:54.440 that's
01:19:05.520 done developers around the world are
01:19:08.080 building the next wave of physical AI
01:19:10.480 embodied robots
01:19:13.000 humanoids developing general purpose
01:19:15.400 robot models requires massive amounts of
01:19:18.080 real world data which is costly to
01:19:20.760 capture and
01:19:21.960 curate Nvidia Isaac Groot helps tackle
01:19:25.080 these challenges providing humanoid
01:19:27.199 robot developers with four things robot
01:19:30.040 Foundation
01:19:31.320 models data
01:19:33.719 pipelines simulation
01:19:36.440 Frameworks and a Thor robotics
01:19:40.719 computer the Nvidia Isaac Groot
01:19:43.120 blueprint for synthetic motion
01:19:44.960 generation is a simulation workflow for
01:19:47.840 imitation learning enabling developers
01:19:50.320 to generate exponentially large data
01:19:52.639 sets from a small number of
01:19:55.639 demonstrations first Groot teleop
01:19:58.560 enables skilled human workers to portal
01:20:01.400 into a digital twin of their robot using
01:20:04.040 the Apple Vision
01:20:05.760 Pro this means operators can capture
01:20:08.320 data even without a physical robot and
01:20:10.840 they can operate the robot in a
01:20:12.320 risk-free environment eliminating the
01:20:14.760 chance of physical damage or wear and
01:20:18.199 tear to teach a robot a single task
01:20:21.600 operators capture motion trajectories
01:20:23.840 through a handful of teleoperated
01:20:26.040 demonstrations then use Groot mimic to
01:20:28.960 multiply these trajectories into a much
01:20:31.480 larger data
01:20:33.440 set next they use Gro gen built on
01:20:37.080 Omniverse and Cosmos for domain
01:20:39.360 randomization and 3D to real
01:20:42.920 upscaling generating an exponentially
01:20:45.679 larger data
01:20:48.120 set the Omniverse and Cosmos Multiverse
01:20:51.239 simulation engine provides a massively
01:20:53.960 scaled data set to train the robot
01:20:57.400 policy once the policy is trained
01:21:00.080 developers can perform software in the
01:21:02.360 loop testing and validation in Isaac Sim
01:21:05.600 before deploying to the real
01:21:08.679 robot the age of General robotics is
01:21:11.400 arriving powered by Nvidia Isaac
01:21:18.040 Groot we're going to have mountains of
01:21:20.400 data to train robots with
01:21:24.840 Nvidia Isaac group Nvidia Isaac group
01:21:28.320 this is our platform to provide
01:21:30.239 technology platform technology elements
01:21:32.639 to the robotics industry to accelerate
01:21:34.920 the development of General
01:21:36.400 Robotics and um well I have one more
01:21:39.880 thing that I want to show you none of
01:21:41.960 none of this none of this would be
01:21:43.520 possible if not for uh this incredible
01:21:47.120 project that we started uh about a
01:21:49.239 decade ago inside the company what
01:21:51.199 called project project digits deep
01:21:54.600 learning GPU intelligence training
01:21:58.840 system
01:22:00.480 digits well before we launched it uh I
01:22:05.199 shrunk it to
01:22:06.600 dgx and to harmonize it with
01:22:09.679 RTX agx ovx and all of the other X's
01:22:13.920 that we have in the company and and um I
01:22:18.560 and and it really revolutionized uh djx1
01:22:21.440 really
01:22:22.239 revolutionized where where's djx1
01:22:25.280 dgx-1 revolutionized artificial
01:22:28.120 intelligence the reason why we built it
01:22:30.880 was because we wanted to uh make it
01:22:33.560 possible for researchers and startups to
01:22:35.520 have an out-of-the-box AI supercomputer
01:22:38.159 imagine the way supercomputers were
01:22:39.560 built in the past you really have to uh
01:22:42.400 build your own facility and you have to
01:22:43.880 go build your own infrastructure and
01:22:45.719 really engineer it into existence and so
01:22:48.120 we created a supercomputer for AI for AI
01:22:51.199 development for researchers and and
01:22:52.639 startups that comes literally one out of
01:22:54.800 the box I delivered the first one to a
01:22:56.920 startup company in 2016 called open Ai
01:23:00.520 and Elon was there and and Ilia sus was
01:23:02.920 there and many of Nvidia Engineers were
01:23:05.120 there and and um uh we we celebrated the
01:23:07.920 arrival of djx1 and obviously uh it
01:23:12.440 revolutionized uh artificial
01:23:14.040 intelligence and Computing um but now
01:23:16.600 artificial intelligence is everywhere
01:23:18.120 it's not just in researchers and and and
01:23:20.320 startup Labs you know we want artificial
01:23:22.639 intelligence as I mentioned in the
01:23:23.800 beginning of our
01:23:25.280 this is now the new way of doing
01:23:27.000 Computing this is the new way of doing
01:23:28.560 software every software engineer every
01:23:30.679 engineer every creative artist everybody
01:23:33.880 who uses computers today as a tool will
01:23:37.600 need a AI
01:23:39.480 supercomputer and so I just wished I
01:23:42.480 just wish that djx1 was smaller and
01:23:49.040 um you know so so um you know imagine
01:23:55.719 ladies and gentlemen
01:24:04.960 our this is nvidia's latest AI
01:24:12.239 supercomputer and and it's finally
01:24:15.320 called project digits right now and if
01:24:19.199 you have a good name for it uh reach out
01:24:20.920 to us um uh this here's the amazing
01:24:25.440 thing this is an AI supercomputer it
01:24:27.159 runs the entire Nvidia AI
01:24:30.520 stack all of nvidia's software runs on
01:24:33.120 this dgx Cloud runs on
01:24:36.280 this this
01:24:38.159 sits well somewhere and it's wireless or
01:24:41.480 you know connect it to your computer
01:24:43.040 it's even a workstation if you like it
01:24:44.480 to be and you could access it you could
01:24:47.520 you could reach it like a like a cloud
01:24:50.679 supercomputer and nvidia's AI works on
01:24:53.280 it and um it's based on a a super secret
01:24:56.880 chip that we've been working on called
01:24:58.880 GB 110 the smallest Grace Blackwell that
01:25:02.840 we make and I have well you know what
01:25:05.719 let's show let's show everybody insight
01:25:34.520 isn't it just isn't just it's just so
01:25:37.239 cute and this is the chip that's
01:25:40.320 inside it is in it is in
01:25:43.239 production this top secret chip uh we
01:25:46.520 did in collaboration the CPU the gray
01:25:48.719 CPU was a uh is built for NVIDIA in
01:25:52.719 collaboration with mediatech
01:25:55.080 uh they're the world's leading s so
01:25:56.719 company and they worked with us to build
01:25:58.840 this CPU this CPU s so and connect it
01:26:02.159 with chipto chip mvy link to the
01:26:04.719 Blackwell GPU and uh this little this
01:26:08.440 little thing here is in full production
01:26:11.320 uh we're expecting this computer to uh
01:26:14.280 be available uh around May time frame
01:26:17.400 and so it's coming at you uh it's just
01:26:19.840 incredible what we could do and it's
01:26:22.080 just I think it's you
01:26:26.480 really I was trying to figure out do I
01:26:28.600 need more hands or more
01:26:30.360 pockets all right so so uh imagine this
01:26:33.920 is what it looks
01:26:35.520 like you know who doesn't want one of
01:26:38.159 those and if you if you use
01:26:41.760 PC Mac you know anything because because
01:26:46.400 uh you know it's it's a cloud platform
01:26:48.360 it's a cloud computing platform that
01:26:49.760 sits on your desk you could also use it
01:26:51.719 as a l Linux workstation if you like uh
01:26:54.320 if you would like to have double
01:26:56.639 digits this is what it looks like you
01:26:59.480 know and you you connect it you connect
01:27:01.679 it together uh uh with connectx and it
01:27:05.239 has
01:27:06.480 nickel GPU direct all of that out of the
01:27:10.520 box it's like a supercomputer our entire
01:27:12.560 supercomputing stack uh is available and
01:27:15.960 so Nvidia Project digits
01:27:28.280 okay well let me let me let me tell you
01:27:31.040 what I told you I told you that we are
01:27:33.880 in production with three new Blackwells
01:27:38.840 not only is the grace Blackwell
01:27:40.840 supercomputers mvlink 72s in production
01:27:43.480 all over the world we now have three new
01:27:46.320 Blackwell systems in production one
01:27:49.719 amazing AI foundational M World
01:27:53.239 Foundation model the world's first
01:27:55.239 physical AI Foundation model is open
01:27:58.000 available to activate the world's
01:28:00.280 industries of Robotics and such and
01:28:03.800 three and three robotics three robots
01:28:07.119 working on uh agentic AI uh human or
01:28:10.920 robots and self-driving
01:28:12.760 cars uh it's been an incredible year I
01:28:15.840 want to thank all of you for your
01:28:16.960 partnership uh thank all of you for
01:28:18.760 coming I made you a short video to
01:28:20.520 reflect on last year and look forward to
01:28:22.440 the next year play please w
01:31:14.760 have a great C us
01:31:17.360 everybody happy New
01:31:19.600 Year thank you
